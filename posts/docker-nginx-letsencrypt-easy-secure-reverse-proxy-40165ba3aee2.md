---
card: "/images/default.jpg"
tags: [Nginx]
description: "by Kasper Siig"
author: "Milad E. Fahmy"
title: "How to set up an easy and secure reverse proxy with Docker, Nginx & Letsencrypt"
created: "2021-08-16T11:30:22+02:00"
modified: "2021-08-16T11:30:22+02:00"
---
<div class="site-wrapper">
<main id="site-main" class="site-main outer">
<div class="inner">
<article class="post-full post tag-nginx tag-docker tag-security tag-tech tag-technology ">
<header class="post-full-header">
<h1 class="post-full-title">How to set up an easy and secure reverse proxy with Docker, Nginx &amp; Letsencrypt</h1>
</header>
<figure class="post-full-image">
<picture>
<source media="(max-width: 700px)" sizes="1px" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 1w">
<source media="(min-width: 701px)" sizes="(max-width: 800px) 400px,
(max-width: 1170px) 700px,
1400px" srcset="/news/content/images/size/w300/2020/04/john-salvino-bqGBbLq_yfc-unsplash.jpg 300w,
/news/content/images/size/w600/2020/04/john-salvino-bqGBbLq_yfc-unsplash.jpg 600w,
/news/content/images/size/w1000/2020/04/john-salvino-bqGBbLq_yfc-unsplash.jpg 1000w,
/news/content/images/size/w2000/2020/04/john-salvino-bqGBbLq_yfc-unsplash.jpg 2000w">
<img onerror="this.style.display='none'" src="/news/content/images/size/w2000/2020/04/john-salvino-bqGBbLq_yfc-unsplash.jpg" alt="How to set up an easy and secure reverse proxy with Docker, Nginx &amp; Letsencrypt">
</picture>
</figure>
<section class="post-full-content">
<div class="post-content medium-migrated-article">
<p>by Kasper Siig</p><h2 id="introduction">Introduction</h2><p>Ever tried setting up some sort of server at home? Where you have to open a new port for every service? And have to remember what port goes to which service, and what your home ip is? This is definitely something that works, and people have been doing it for the longest time.</p><p>However, wouldn’t it be nice to type <em>plex.example.com</em>, and have instant access to your media server? This is exactly what a reverse proxy will do for you, and combining it with Docker, it’s easier than ever.</p><h2 id="prerequisites">Prerequisites</h2><h3 id="docker-docker-compose">Docker &amp; Docker-Compose</h3><p>You should have Docker version 17.12.0+, and Compose version 1.21.0+.</p><h3 id="domain">Domain</h3><p>You should have a domain set up, and have an SSL Certificate associated with it. If you don’t have one, then <a href="https://medium.com/devopslinks/docker-letsencrypt-dns-validation-75ba8c08a0d" rel="noopener">follow my guide here</a> on how to get a free one with LetsEncrypt.</p><h2 id="what-this-article-will-cover">What This Article Will Cover</h2><p>I’m a firm believer in understanding what you are doing. There was a time where I would follow guides, and have no clue on how to troubleshoot failures. If that’s how you want to do it, <a href="https://medium.freecodecamp.org/docker-compose-nginx-and-letsencrypt-setting-up-website-to-do-all-the-things-for-that-https-7cb0bf774b7e" rel="noopener">here’s a great tutorial</a>, which covers how to set it up. While my articles are lengthy, you should end up with an understanding of how it all works.</p><p>What you will learn here, is what a reverse proxy is, how to set it up, and how you can secure it. I do my best to divide the subject into sections, divided by headers, so feel free to jump over a section, if you feel like it. I recommend reading the entire article one time first, before starting to set it up.</p><h2 id="what-is-a-reverse-proxy">What is a Reverse Proxy?</h2><h3 id="regular-proxy">Regular Proxy</h3><p>Let’s start with the concept of a regular proxy. While this is a term that’s very prevalent in the tech community, it is not the only place it’s used. A proxy means that information is going through a third party, before getting to the location.</p><p>Say that you don’t want a service to know your IP, you can use a proxy. A proxy is a server that has been set up specifically for this purpose. If the proxy server you are using is located in, for example, Amsterdam, the IP that will be shown to the outside world is the IP from the server in Amsterdam. The only ones who will know your IP are the ones in control of the proxy server.</p><h3 id="reverse-proxy">Reverse Proxy</h3><p>To break it into simple terms, a proxy will add a layer of masking. It’s the same concept in a reverse proxy, except instead of masking outgoing connections (you accessing a webserver), it’s the incoming connections (people accessing your webserver) that will be masked. You simply provide a URL like <em>example.com</em>, and whenever people access that URL, your reverse proxy will take care of where that request goes.</p><p>Let’s say you have two servers set up on your internal network. Server1 is on <em>192.168.1.10</em>, and Server2 is on <em>192.168.1.20.</em> Right now your reverse proxy is sending requests coming from <em>example.com</em> to Server1. One day you have some updates to the webpage. Instead of taking the website down for maintenance, you just make the new setup on Server2. One you’re done, you simply change a single line in your reverse proxy, and now requests are sent to Server2. Assuming the reverse proxy is setup correctly, you should have absolutely no downtime.</p><p>But perhaps the biggest advantage of having a reverse proxy, is that you can have services running on a multitude of ports, but you only have to open ports 80 and 443, HTTP and HTTPS respectively. All requests will be coming into your network on those two ports, and the reverse proxy will take care of the rest. All of this will make sense once we start setting the proxy up.</p><h2 id="setting-up-the-container">Setting Up the Container</h2><h3 id="what-to-do">What to Do</h3><p><code>docker-compose.yaml</code>:</p><pre><code class="language-yaml">version: '3'
services:
reverse:
container_name: reverse
hostname: reverse
image: nginx
ports:
- 80:80
- 443:443
volumes:
- &lt;path/to/your/config&gt;:/etc/nginx
- &lt;path/to/your/certs&gt;:/etc/ssl/private</code></pre><p>First of all, you should add a new service to your docker-compose file. You can call it whatever you prefer, in this case I’ve chosen <em>reverse</em>. Here I’ve just chosen <em>nginx</em> as the image, however in a production environment, it’s usually a good idea to specify a version in case there are ever any breaking changes in future updates.</p><p>Then you should volume bind two folders. <em>/etc/nginx</em> is where all your configuration files are stored, and <em>/etc/ssl/private</em> is where your SSL certificates are stored. It is VERY important that your config folder does NOT exist on your host first time you’re starting the container. When you start your container through docker-compose, it will automatically create the folder and populate it with the contents of the container. If you have created an empty config folder on your host, it will mount that, and the folder inside the container will be empty.</p><h3 id="why-it-works">Why it Works</h3><p>There isn’t much to this part. Mostly it’s like starting any other container with docker-compose. What you should notice here is that you are binding port 80 and 443. This is where all requests will come in, and they will be forwarded to whatever service you will specify.</p><h2 id="configuring-nginx">Configuring Nginx</h2><h3 id="what-to-do-1">What to Do</h3><p>Now you should have a config folder on your host. Changing to that directory, you should see a bunch of different files and a folder called <code>conf.d</code>. It’s inside <code>conf.d</code> that all your configuration files will be placed. Right now there’s a single <code>default.conf</code> file, you can go ahead and delete that.</p><p>Still inside <code>conf.d</code>, create two folders: <code>sites-available</code> and <code>sites-enabled</code>. Navigate into <code>sites-available</code> and create your first configuration file. Here we’re going to setup an entry for <a href="https://plex.tv" rel="noopener">Plex</a>, but feel free to use another service that you have set up if you like. It doesn’t really matter what the file is called, however I prefer to name it like <code>plex.conf</code>.</p><p>Now open the file, and enter the following:</p><pre><code>upstream plex {
server  plex:32400;
}
server {
listen  80;
server_name   plex.example.com;
location / {
proxy_pass  http://plex;
}
}</code></pre><p>Go into the <code>sites-enabled</code> directory, and enter the following command:</p><pre><code>ln -s ../sites-available/plex.conf .</code></pre><p>This will create a symbolic link to the file in the other folder. Now there’s only one thing left, and that is to change the <code>nginx.conf</code> file in the config folder. If you open the file, you should see the following as the last line:</p><pre><code>include /etc/nginx/conf.d/*.conf;</code></pre><p>Change that to:</p><pre><code>include /etc/nginx/conf.d/sites-enabled/*.conf;</code></pre><p>In order to get the reverse proxy to actually work, we need to reload the nginx service inside the container. From the host, run <code>docker exec &lt;container-name&gt; nginx -t</code>. This will run a syntax checker against your configuration files. This should output that the syntax is ok. Now run <code>docker exec &lt;container-name&gt; nginx -s reload</code>. This will send a signal to the nginx process that it should reload, and congratulations! You now have a running reverse proxy, and should be able to access your server at <em><em>plex.example.com </em></em>(assuming that you have forwarded port 80 to your host in your router).</p><p>Even though your reverse proxy is working, you are running on HTTP, which provides no encryption whatsoever. The next part will be how to secure your proxy, and get a perfect score on <a href="https://www.ssllabs.com/ssltest/analyze.html" rel="noopener">SSL Labs</a>.</p><h3 id="why-it-works-1">Why it Works</h3><p><strong>The Configuration File</strong></p><p>As you can see, the <code>plex.conf</code> file consists of two parts. An <code>upstream</code> part and a <code>server</code> part. Let’s start with the <code>server</code> part. This is where you are defining the port receiving the incoming requests, what domain this configuration should match, and where it should be sent to.</p><p>The way this server is being set up, you should make a file for each service that you want to proxy requests to, so obviously you need some way to distinguish which file to receive each request. This is what the <code>server-name</code> directive does. Below that we have the <code>location</code> directive.</p><p>In our case we only need one <code>location</code>, however you can have as many <code>location</code> directives as you want. Imagine you have a website with a frontend and a backend. Depending on the infrastructure you’re using, you’ll have the frontend as one container and the backend as another container. You could then have <code>location / {}</code> which will send requests to the frontend, and <code>location /api/ {}</code> which will send requests to the backend. Suddenly you have multiple services running on a single memorable domain.</p><p>As for the <code>upstream</code> part, that can be used for load-balancing. If you’re interested in learning more about how that works, you can look at the <a href="http://nginx.org/en/docs/http/ngx_http_upstream_module.html">official docs here</a>. For our simple case, you just define the hostname or ip address of the service you want to proxy to, and what port is should be proxied to, and then refer to the upstream name in the <code>location</code> directive.</p><p><strong>Hostname Vs. IP Address</strong></p><p>To understand what a hostname is, let’s make an example. Say you are on your home network <em>192.168.1.0.</em> You then set up a server on <em>192.168.1.10</em> and run Plex on it. You can now access Plex on <em>192.168.1.10:32400</em>, as long as you are still on the same network. Another possibility is to give the server a hostname. In this case we’ll give it the hostname <em>plex</em>. Now you can access Plex by entering <em>plex:32400 </em>in your browser!</p><p>This same concept was introduced to docker-compose in version 3. If you look at the docker-compose file earlier in this article, you’ll notice that I gave it a <code>hostname: reverse</code> directive. Now all other containers can access my reverse proxy by its hostname. One thing that’s very important to note, is that the service name has to be the same as the hostname. This is something that the creators of docker-compose chose to impose.</p><p>Another really important thing to remember, is that by default docker containers are put on their own network. This means that you won’t be able to access your container by it’s hostname, if you’re sitting on your laptop on your host network. It is only the containers that are able to access each other through their hostname.</p><p>So to sum it up and make it really clear. In your docker-compose file, add the <code>hostname</code> directive to your services. Most of the time your containers will get a new IP every time you restart the container, so referring to it via hostname, means it doesn’t matter what IP your container is getting.</p><p><strong>Sites-available &amp; Sites-enabled</strong></p><p>Why are we creating the <code>sites-available</code> and <code>sites-enabled</code> directories? This is not something of my creation. If you install Nginx on a server, you will see that it comes with these folders. However because Docker is built with microservices in mind, where one container should only ever do one thing, these folders are omitted in the container. We’re recreating them again, because of how we’re using the container.</p><p>And yes, you could definitely just make a <code>sites-enabled</code> folder, or directly host your configuration files in <code>conf.d</code>. Doing it this way, enables you to have passive configuration laying around. Say that you are doing maintenance, and don’t want to have the service active; you simply remove the symbolic link, and put it back when you want the service active again.</p><p><strong>Symbolic Links</strong></p><p>Symbolic links are a very powerful feature of the operating system. I had personally never used them before setting up an Nginx server, but since then I’ve been using them everywhere I can. Say you are working on 5 different projects, but all these projects use the same file in some way. You can either copy the file into every project, and refer to it directly, or you can place the file in one place, and in those 5 projects make symlinks to that file.</p><p>This gives two advantages: you take up 4 times less space than you otherwise would have, and then the most powerful of them all; change the file in one place, and it changes in all 5 projects at once! This was a bit of a sidestep, but I think it’s worth mentioning.</p><h2 id="securing-nginx-proxy">Securing Nginx Proxy</h2><h3 id="what-to-do-2">What to Do</h3><p>Go to your config folder, and create 3 files and fill them with the following input:</p><p><code>common.conf</code>:</p><pre><code>add_header Strict-Transport-Security    "max-age=31536000; includeSubDomains" always;
add_header X-Frame-Options        SAMEORIGIN;
add_header X-Content-Type-Options nosniff;
add_header X-XSS-Protection       "1; mode=block";</code></pre><p><code>common_location.conf</code>:</p><pre><code>proxy_set_header    X-Real-IP           $remote_addr;
proxy_set_header    X-Forwarded-For     $proxy_add_x_forwarded_for;
proxy_set_header    X-Forwarded-Proto   $scheme;
proxy_set_header    Host          $host;
proxy_set_header    X-Forwarded-Host    $host;
proxy_set_header    X-Forwarded-Port    $server_port;</code></pre><p><code>ssl.conf</code>:</p><pre><code>ssl_protocols         TLSv1 TLSv1.1 TLSv1.2;
ssl_ecdh_curve        secp384r1;
ssl_ciphers           "ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384 OLD_TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 OLD_TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256";
ssl_prefer_server_ciphers   on;
ssl_dhparam           /etc/nginx/dhparams.pem;
ssl_certificate       /etc/ssl/private/fullchain.pem;
ssl_certificate_key   /etc/ssl/private/privkey.pem;
ssl_session_timeout   10m;
ssl_session_cache     shared:SSL:10m;
ssl_session_tickets   off;
ssl_stapling          on;
ssl_stapling_verify   on;</code></pre><p>Now open the <code>plex.conf</code> file, and change it to the following (notice lines 6, 9, 10 &amp; 14):</p><pre><code>upstream plex {
server  plex:32400;
}
server {
listen  443 ssl;
server_name   plex.example.com;
include common.conf;
include /etc/nginx/ssl.conf;
location / {
proxy_pass  http://plex;
include     common_location.conf;
}
}</code></pre><p>Now go back to the root of your config folder, and run the following command:</p><pre><code>openssl dhparam -out dhparams.pem 4096</code></pre><p>This will take a long time to complete, even up to an hour in some cases.</p><p>If you followed my article on getting a LetsEncrypt SSL Certificate, your certificates should be located in <code>&lt;/path/to/your/letsencrypt/config&gt;/etc/letsencrypt/live/&lt;domain&gt;/</code> .</p><p>When I helped a friend set this up on his system, we ran into some problems where it couldn’t open the files when they were located in that directory. Most likely the cause of some permissions problems. The easy solution to this is to make an SSL directory, like <code>&lt;/path/to/your/nginx/config&gt;/certs</code>, and then mount that to the Nginx container’s <code>/etc/ssl/private</code> folder. In the newly created folder, you should then make symbolic links, to the certs in your LetsEncrypt’s config folder.</p><p>When the <code>openssl</code> command is done running, you should run the <code>docker exec &lt;container-name&gt; nginx -t</code> to make sure that all the syntax is correct, and then reload it by running <code>docker exec &lt;container-name&gt; nginx -s reload</code>. At this point everything should be running, and you now have a working and perfectly secure reverse proxy!</p><h3 id="why-it-works-2">Why it Works</h3><p>Looking in the <code>plex.conf</code> file, there is only one major change, and that is what port the reverse proxy is listening on, and telling it that it’s an ssl connection. Then there are 3 places where we’re including the 3 other files we made. While SSL is kind of secure by itself, these other files make it even more secure. However if for some reason you don’t want to include these files, you need to move the <code>ssl-certificate</code> and <code>ssl-certificate-key</code>inside the <code>.conf</code> file. These are required to have, in order for an HTTPS connection to work.</p><p><strong>Common.conf</strong></p><p>Looking in the <code>common.conf</code> file, we add 4 different headers. Headers are something that the server sends to the browser on every response. These headers tell the browser to act a certain way, and it is then up to the browser to enforce these headers.</p><p><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security" rel="noopener"><strong>Strict-Transport-Security (HSTS)</strong></a></p><p>This header tells the browser that connections should be made over HTTPS. When this header has been added, the browser won’t let you make plain HTTP connection to the server, ensuring that all communication is secure.</p><p><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options" rel="noopener"><strong>X-Frame-Options</strong></a></p><p>When specifying this header, you are specifying whether or not other sites can embed your content into their sites. This can help avoid <a href="https://en.wikipedia.org/wiki/Clickjacking" rel="noopener">clickjacking</a> attacks.</p><p><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Content-Type-Options" rel="noopener"><strong>X-Content-Type-Options</strong></a></p><p>Say you have a site where users can upload files. There’s not enough validation on the files, so a user successfully uploads a <code>php</code> file to the server, where the server is expecting an image to be uploaded. The attacker may then be able to access the uploaded file. Now the server responds with an image, however the file’s MIME-type is <code>text/plain</code>. The browser will ‘sniff’ the file, and then render the php script, allowing the attacker to do RCE (Remote Code Execution).</p><p>With this header set to ‘nosniff’, the browser will not look at the file, and simply render it as whatever the server tells the browser that it is.</p><p><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-XSS-Protection" rel="noopener"><strong>X-XSS-Protection</strong></a></p><p>While this header was more necessary in older browsers, it’s so easy to add that you might as well. Some XSS (Cross-site Scripting) attacks can be very intelligent, while some are very rudimentary. This header will tell browsers to scan for the simple vulnerabilities and block them.</p><p><strong>Common_location.conf</strong></p><p><strong>X-Real-IP</strong></p><p>Because your servers are behind a reverse proxy, if you try to look at the requesting IP, you will always see the IP of the reverse proxy. This header is added so you can see which IP is actually requesting your service.</p><p><strong>X-Forwarded-For</strong></p><p>Sometimes a users request will go through multiple clients before it reaches your server. This header includes an array of all those clients.</p><p><strong>X-Forwarded-Proto</strong></p><p>This header will show what protocol is being used between client and server.</p><p><strong>Host</strong></p><p>This ensures that it’s possible to do a reverse DNS lookup on the domain name. It’s used when the <code>server_name</code> directive is different than what you are proxying to.</p><p><strong>X-Forwarded-Host</strong></p><p>Shows what the real host of the request is instead of the reverse proxy.</p><p><strong>X-Forwarded-Port</strong></p><p>Helps identify what port the client requested the server on.</p><p><strong>Ssl.conf</strong></p><p>SSL is a huge topic in and of itself, and too big to start explaining in this article. There are many great tutorials out there on how SSL handshakes work, and so on. If you want to look into this specific file, I suggest looking at the protocols and ciphers being used, and what difference they make.</p><h2 id="redirecting-http-to-https">Redirecting HTTP to HTTPS</h2><p>The observant ones have maybe noticed that we are only ever listening on port 443 in this secure version. This would mean that anyone trying to access the site via <em>https://*</em> would get through, but trying to connect through <em>http://*</em> would just get an error. Luckily there’s a really easy fix to this. Make a <code>redirect.conf</code> file with the following contents:</p><pre><code>server {
listen  80;
server_name   _;
return 301 https://$host$request_uri;
}</code></pre><p>Now just make sure that it appears in your <code>sites-enabled</code> folder, and when you’ve reloaded the Nginx process in the container, all requests to port 80 will be redirected to port 443 (HTTPS).</p><h2 id="final-thoughts">Final Thoughts</h2><p>Now that your site is up and running, you can head over to <a href="https://www.ssllabs.com/ssltest/analyze.html" rel="noopener">SSL Labs</a> and run a test to see how secure your site is. At the time of writing this, you should get a perfect score. However there is a big thing to notice about that.</p><p>There will always be a balance between security and convenience. In this case the weights are heavily on the side of security. If you run the test on SSL Labs and scroll down, you will see there are multiple devices that won’t be able to connect with your site, because they don’t support new standards.</p><p>So have this in mind when you are setting this up. Right now I am just running a server at home, where I don’t have to worry about that many people being able to access it. But if you do a scan on Facebook, you’ll see they won’t have as great a score, however their site can be accessed by more devices.</p>
</div>
<hr>
</section>
</article>
</div>
</main>
</div>
<!-- Google Tag Manager (noscript) -->
<!-- End Google Tag Manager (noscript) -->
