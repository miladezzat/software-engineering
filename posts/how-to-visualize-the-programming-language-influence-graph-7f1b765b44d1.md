---
card: "https://cdn-media-1.freecodecamp.org/images/1*B2TjLzIuTc7OgugSSt-VAA.png"
tags: [Python]
description: "Here’s a preview of what we’ll be making today: the programmi"
author: "Milad E. Fahmy"
title: "Visualize the programming language influence graph"
created: "2021-08-16T15:41:57+02:00"
modified: "2021-08-16T15:41:57+02:00"
---
<div class="site-wrapper">
<main id="site-main" class="site-main outer">
<div class="inner">
<article class="post-full post tag-python tag-tech tag-technology tag-programming tag-tutorial tag-gephi tag-data-science tag-data tag-network ">
<header class="post-full-header">
<h1 class="post-full-title">Visualize the programming language influence graph</h1>
</header>
<figure class="post-full-image">
<picture>
<source media="(max-width: 700px)" sizes="1px" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 1w">
<source media="(min-width: 701px)" sizes="(max-width: 800px) 400px,
(max-width: 1170px) 700px,
1400px" srcset="https://cdn-media-1.freecodecamp.org/images/1*B2TjLzIuTc7OgugSSt-VAA.png 300w,
https://cdn-media-1.freecodecamp.org/images/1*B2TjLzIuTc7OgugSSt-VAA.png 600w,
https://cdn-media-1.freecodecamp.org/images/1*B2TjLzIuTc7OgugSSt-VAA.png 1000w,
https://cdn-media-1.freecodecamp.org/images/1*B2TjLzIuTc7OgugSSt-VAA.png 2000w">
<img onerror="this.style.display='none'" src="https://cdn-media-1.freecodecamp.org/images/1*B2TjLzIuTc7OgugSSt-VAA.png" alt="Visualize the programming language influence graph">
</picture>
</figure>
<section class="post-full-content">
<div class="post-content">
Python     0    1     0  0
Java 0    0     0  1
Scala0    1     0  0
C#   0    1     0  0</code></pre><p>In this matrix, the intersection of each row and column is either 0 or 1, depending on whether or not the respective languages are linked. You can check this against the illustration above!</p><p>For most purposes, the adjacency matrix is a good way of representing a network mathematically. From a computational perspective, however, it can sometimes be a bit cumbersome.</p><p>For instance, with even a relatively modest number of nodes (say 1000), there will be a much larger number of elements in the matrix (e.g., 1000² = 1,000,000).</p><p>Many real-world systems yield <strong>sparse networks</strong>. In these networks, most nodes only connect to a small proportion of all the others.</p><p>If we represented a 1000-node sparse network in computer memory as an adjacency matrix, we’d have 1,000,000 bytes of data stored in RAM. Most will be zeros. There’s got to be a more efficient way of going about this.</p><p>An alternative approach is to work with <strong>edge lists</strong><em> </em>instead. These are exactly what they say they are. They are simply a list of which node pairs link to each other.</p><p>For example, the programming languages network above can be represented as follows:</p><pre><code>Java, Python
Java, Scala
Java, C#
C#, Java</code></pre><p>For larger networks, this is a much more computationally efficient means of representing them. It is of course possible to generate an adjacency matrix from an edge list (and vice versa). It’s not like we have to pick one or the other.</p><p>Another means of representing networks are <a href="https://en.wikipedia.org/wiki/Adjacency_list" rel="noopener">adjacency lists</a>. This lists every node followed by the nodes it links to. For example:</p><pre><code>Java: Python, Scala, C#
C#: Java</code></pre><h3 id="collecting-data-making-connections">Collecting data, making connections</h3><p>Any network model and visualisation will only be as good as the data used to construct it. This means, as well as ensuring the data is both accurate and complete, we also need to justify a means of inferring edges between nodes.</p><p>In many respects, this is <em>the</em> critical step. Any subsequent analysis and inferences made about the network depend on being able to justify the “linkage criterion”.</p><p>For example, in <a href="https://en.wikipedia.org/wiki/Social_network_analysis" rel="noopener">social network analysis</a>, you might link people based upon whether they follow one another on social media. In molecular biology, you might link genes based upon their <a href="https://en.wikipedia.org/wiki/Gene_co-expression_network" rel="noopener">co-expression</a>.</p><p>Often, the method used to link nodes will allow for <strong>weights</strong> to be assigned to the edges, giving a measure of “strength”.</p><p>For instance, in the context of online retail, you could link products based upon how often they are purchased together. Products that are frequently bought together would be linked by a higher <strong>weighted edge</strong> than products which are only sometimes bought together. Products that are bought together no more often than would be expected by chance wouldn’t be linked at all.</p><p>As you might imagine, the methods for linking nodes to one another can be as sophisticated as you like.</p><p>However, for this tutorial we’ll be using a simpler means of connecting programming languages. We’re gonna rely on the accuracy of Wikipedia.</p><p>For our purposes, this should be fine. Wikipedia’s success is testament that it must be doing something right. The open-source, collaborative method by which articles are written should ensure some degree of objectivity.</p><p>Also, its relatively consistent page structure makes it a convenient playground for trying out web-scraping techniques.</p><p>Another bonus is the extensive, <a href="https://www.mediawiki.org/wiki/API:Main_page" rel="noopener">well-documented Wikipedia API</a>, which makes information retrieval easier still. Let’s get started.</p><h3 id="step-1-installing-gephi">Step 1 — Installing Gephi</h3><p>Gephi is available on Linux, Mac and Windows. You can download it <a href="https://gephi.org/users/download/" rel="noopener">here</a>.</p><p>For this project, I was using Lubuntu. If you’re on Ubuntu/Debian, then you can follow the steps below to get Gephi up and running. Otherwise, the installation process will likely be much the same as whatever you’re familiar with.</p><p>Download the latest version (at the time of writing this was v.0.9.1) of Gephi for your system. When it’s ready, you’ll need to extract the files.</p><pre><code>cd Downloads
tar -xvzf gephi-0.9.1-linux.tar.gz
cd gephi-0.9.1/bin./gephi</code></pre><p>You may need to check your version of the Java JRE. Gephi requires a recent version. On my relatively fresh install of Lubuntu, I simply installed the default-jre, and everything worked from there.</p><pre><code>apt install default-jre
./gephi</code></pre><p>There’s one more step before you’re ready to get underway. In order to export the graph to the Web, you can use the <a href="http://sigmajs.org/" rel="noopener">Sigma.js</a> plugin for Gephi.</p><p>From Gephi’s menu bar, choose the “Tools” option, and select “Plugins”.</p><p>Click on the “Available Plugins” tab and select “SigmaExporter” (I also installed JSON Exporter, because it’s another useful plugin to have around).</p><p>Hit the “Install” button and you’ll be walked through the process. You’ll need to restart Gephi once you’re done.</p><h3 id="step-2-writing-the-python-script">Step 2 — Writing the Python script</h3><p>This tutorial will use Python 3.x, plus a few modules to make life easier. Using the pip module installer, run the following command:</p><pre><code>pip3 install wikipedia</code></pre><p>Now, in a new directory, create a file called something like <code>script.py</code>, and open it up in your favourite code editor/IDE. Below is an outline of the main logic:</p><ol><li>First, you’ll need a <a href="https://en.wikipedia.org/wiki/List_of_programming_languages" rel="noopener">list of programming languages</a> to include.</li><li>Next, go through that list and retrieve the HTML of the relevant Wikipedia article.</li><li>From this, extract a list of programming languages that each language has influenced. This will be a rough-and-ready linkage criterion.</li><li>While you’re at it, it’d be nice to grab some metadata about each language.</li><li>Finally, you’ll want to write all the data you’ve collected to a .csv file</li></ol><p>The full script can be found in <a href="https://gist.github.com/anonymous/2a6c841fe04ebc6d55acc259b4ac4f72" rel="noopener">this gist</a>.</p><h4 id="import-some-modules">Import some modules</h4><p>In <code>script.py</code>, start by importing a few modules which will make things easier:</p><pre><code class="language-Python">import csv
import wikipedia
import urllib.request
from bs4 import BeautifulSoup as BS
import re</code></pre><p>OK — begin by making a list of nodes to include. This is where the <a href="https://github.com/goldsmith/Wikipedia" rel="noopener">Wikipedia</a> module comes in handy. It makes accessing the <a href="https://www.mediawiki.org/wiki/API:Main_page" rel="noopener">Wikipedia API </a>super-easy.</p><p>Add the following code:</p><pre><code class="language-Python">pageTitle = "List of programming languages"
nodes = list(wikipedia.page(pageTitle).links)
print(nodes)</code></pre><p>If you save and run this script, you’ll see it prints out all the links from the <a href="https://en.wikipedia.org/wiki/List_of_programming_languages" rel="noopener">“List of programming languages”</a> Wikipedia article. Nice!</p><p>However, it’s always sensible to manually inspect any automatically collected data. A quick glance will reveal that, as well as many actual programming languages, the script has also picked up a few extra links.</p><p>For example, you might see “<a href="https://en.wikipedia.org/wiki/List_of_markup_languages" rel="noopener">List of markup languages</a>”, “<a href="https://en.wikipedia.org/wiki/Comparison_of_programming_languages" rel="noopener">Comparison of programming languages</a>” and others in there.</p><p>Although Gephi lets you remove nodes you’d rather not include, it wouldn’t hurt to “clean” the data before proceeding. If anything, this will save time later on.</p><pre><code class="language-Python">removeList = [
"List of",
"Lists of",
"Timeline",
"Comparison of",
"History of",
"Esoteric programming language"
]
nodes = [i for i in nodes if not any(r in i for r in removeList)]</code></pre><p>These lines define a list of substrings to be removed from the data. The script then goes through the data, removing any elements that contain any of the unwanted substrings.</p><p>In Python, this requires just one line of code!</p><h4 id="some-helper-functions">Some helper functions</h4><p>Now you can start scraping Wikipedia to build up an edge list (and collect any metadata). To make this easier, first define a few functions.</p><h4 id="grabbing-html">Grabbing HTML</h4><p>The first function uses the <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener">BeautifulSoup</a> module to get hold of the HTML for each language’s Wikipedia page.</p><pre><code class="language-Python">base = "https://en.wikipedia.org/wiki/"
def getSoup(n):
try:
with urllib.request.urlopen(base+n) as response:
soup = BS(response.read(),'html.parser')
table = soup.find_all("table",class_="infobox vevent")[0]                return table
except:
try:
t = t.get_text()
year = t[t.find("appear"):t.find("appear")+30]
year = re.match(r'.*([1-3][0-9]{3})',year).group(1)
return int(year)
except:
return "Could not determine"</code></pre><p>This short function takes the <code>table</code> object as its argument, and uses BeautifulSoup’s <code>get_text()</code> function to produce a string.</p><p>The next step is to create a substring called <code>year</code>. This takes the 30 characters after the first appearance of the word <code>"appear"</code>. This string should contain the year the language first appeared.</p><p>In order to extract just the year, use a <strong>regular expression</strong> (courtesy of the <code>re</code> module) to match any characters that begin with a digit between 1 and 3, and are followed by three digits.</p><pre><code class="language-Python">re.match(r'.*([1-3][0-9]{3})',year)</code></pre><p>If this is successful, the function returns <code>year</code> as an integer. Otherwise, it returns a sad-looking “Could not determine”. You might wish to scrape further metadata — such as paradigm, designer or typing discipline.</p><h4 id="collecting-links">Collecting links</h4><p>One more function for you — this time, you’ll feed in the <code>table</code> object for a given language, and hopefully receive out a list of other programming languages.</p><pre><code class="language-Python">def getLinks(t):
try:
table_rows = t.find_all("tr")
for i in range(0,len(table_rows)-1):
try:
if table_rows[i].get_text() == "\nInfluenced\n":
out = []
for j in table_rows[i+1].find_all("a"):
try:
out.append(j['title'])
except:
continue
return out
except:
continue
return
except:
return</code></pre><p>Woah, look at all that nesting… What is actually going on here then?</p><p>This function makes use of the fact that the <code>table</code> objects have a consistent structure. The information in the table is stored in rows (the relevant HTML tag is <code>&lt;</code>tr&gt; ). One of these rows will contain the` text <code>"\nInfluenced\n"</code>. The first part of the function finds which row this is.</p><p>Once this row has been found, you can then be pretty sure the next<em> </em>row contains links to each of the programming languages influenced by the current one. Find these links using <code>find_all("a")</code> — where the argument <code>"a"</code> corresponds to the HTML tag <code>&lt;a&gt;</code>.</p><p>For each link <code>j</code>, append its <code>["title"]</code> attribute to a list called <code>out</code>. The reason to be interested in the <code>["title"]</code> attribute is because this will match <em>exactly</em> the language’s name as stored in <code>nodes</code>.</p><p>For example, Java is stored in <code>nodes</code> as <code>"Java (programming language)"</code>, so you need to use this exact name throughout the data set.</p><p>If successful, <code>getLinks()</code> returns a list of programming languages. The rest of the function deals with exception handling, in case something should go wrong at any stage.</p><h4 id="collecting-the-data">Collecting the data</h4><p>At last, you’re almost ready to sit back and let the script do its thing. It will collect the data and store it in two list objects.</p><pre><code class="language-Python">edgeList = [["Source,Target"]]
meta = [["Id","Year"]]</code></pre><p>Now write a loop that will apply the functions defined earlier to every item in <code>nodes</code>, and store the outputs in <code>edgeList</code> and <code>meta</code>.</p><pre><code class="language-Python">for n in nodes:
try:
temp = getSoup(n)
except:
continue
try:
influenced = getLinks(temp)
for link in influenced:
if link in nodes:
edgeList.append([n+","+link])
print([n+","+link])
except:
continue
year = getYear(temp)
meta.append([n,year])</code></pre><p>This function takes each language in <code>nodes</code> and attempts to retrieve the summary table from its Wikipedia page.</p><p>Then, it retrieves all the languages the table lists as having been influenced by the language in question.</p><p>For each language that also appears in the <code>nodes</code> list, append an element to <code>edgeList</code> in the form of <code>["source,target"]</code>. In this way, you’ll build up an edge list to feed into Gephi.</p><p>For debugging purposes, print each element added to <code>edgeList</code> — just to be sure everything’s working as it should. If you were being extra thorough, you could add print statements to the <code>except</code> clauses, too.</p><p>Next, get the language’s name and year, and append these to the <code>meta</code> list.</p><h4 id="writing-to-csv">Writing to CSV</h4><p>Once the loop has run, the final step is to write the contents of <code>edgeList</code> and <code>meta</code> to comma separated value (CSV) files. This is easily done with the <code>csv</code> module imported earlier.</p><pre><code class="language-Python">with open("edge_list.csv","w") as f:
wr = csv.writer(f)
for e in edgeList:
wr.writerow(e)
with open("metadata.csv","w") as f2:
wr = csv.writer(f2)
for m in meta:
wr.writerow(m)</code></pre><p>Done! Save the script, and from the terminal run:</p><p><code>$ python3 script.py</code></p><p>You should see the script printing out each source-target pair as it builds up the edge list. Make sure your internet connection is steady, and sit back while the script does its magic.</p><h3 id="step-3-graph-building-with-gephi">Step 3 — Graph building with Gephi</h3><p>Hopefully you got Gephi installed and running earlier. Now you can create a new project and use the data you gathered to build a directed graph. This will show how different programming languages have influenced one another!</p><p>Start by creating a new project in Gephi, and switch to the “Data Laboratory” view. This provides a spreadsheet-like interface for handling data in Gephi. The first thing to do is import the edge list.</p><ul><li>Click “Import spreadsheet”.</li><li>Choose the <code>edge_list.csv</code> file generated by the Python script. Ensure that Gephi knows to use the commas as the separator.</li><li>Choose “Edge List” from the List type.</li><li>Click “Next” and check that you are importing both Source and Target columns as strings.</li></ul><p>This should update the Data Lab with a list of nodes. Now, import the <code>metadata.csv</code> file. This time, make sure to choose “Nodes list” from the List type.</p><p>Switch over to the “Preview” tab, and see how the network looks.</p><p>Ah… It’s just a little bit… monochrome. And messy. Like a plate of spaghetti. Let’s fix this.</p><h4 id="making-it-pretty">Making it pretty</h4><p>There are all sorts of ways you can work on the presentation, and here’s where a little bit of creative freedom comes in. With network visualisations, there are essentially three things to take into consideration:</p><ol><li><strong>Positioning </strong>There are several algorithms which can generate layout patterns for a network. A popular choice is the <a href="https://schneide.wordpress.com/tag/fruchterman-reingold/" rel="noopener">Fruchterman-Reingold algorithm</a>, which is available in Gephi.</li><li><strong>Sizing </strong>The size of nodes in a graph can be used to represent some interesting property. Often, this is a<strong> centrality measure</strong>. There are <a href="https://en.wikipedia.org/wiki/Centrality" rel="noopener">many ways of measuring centrality</a>, but they all reflect the “importance” of a given node, in terms of how well-connected it is to the rest of the network.</li><li><strong>Coloring </strong>It is also possible to use color to show some property of a node. Often, color is used to indicate <strong>community structure</strong>. This is broadly defined as a “group of nodes which are more connected with each other than with the rest of the graph”. In a social network, this can reveal friendship, family or professional groups. There are several <a href="https://en.wikipedia.org/wiki/Community_structure#Algorithms_for_finding_communities" rel="noopener">algorithms which can detect community structure</a>. Gephi comes with the <a href="https://en.wikipedia.org/wiki/Louvain_Modularity" rel="noopener">Louvain method</a> built-in.</li></ol><p>To make these changes, you will need to calculate some statistics. Switch to the “Overview” window. Here you will see a panel on the right. It should contain a “Statistics” tab. Open this, and you will see a range of options.</p><p>Gephi comes with many inbuilt statistical capabilities. For each of them, clicking “Run” will generate a report that will reveal insights about the network.</p><p>Some useful ones to know include:</p><ul><li><strong>Average degree </strong>The average language is connected to about four others. The report also shows a <a href="https://en.wikipedia.org/wiki/Degree_distribution" rel="noopener">degree distribution</a> graph. This reveals that most languages have very few connections, while a small proportion have many. This suggests that this is a <strong>scale-free</strong> <strong>network</strong>. Much research has been done on <a href="http://barabasi.com/f/124.pdf" rel="noopener">scale-free networks</a>, and the processes that generate them.</li><li><strong>Diameter </strong>This network has a diameter of 12 — meaning this is the “widest” number of connections between any two languages. The average path length is just under four. This means that, on average, any two languages are separated by four edges. These figures give a measure of the “size” of the network.</li><li><strong>Modularity </strong>This is a score that shows how “compartmentalized” the network is. Here, the modularity score is about 0.53. This is relatively high, suggesting there are distinct modules within this network. Again, this indicates something interesting about the underlying system. Languages tend to fall into distinct “influence groups”.</li></ul><p>Anyhow, to modify the appearance of the network, head over to the left panel.</p><p>In the “Layout” tab, you can select which layout algorithm to use. Hit “Run” and watch the graph shift about in real-time! See which layout algorithm you think works best.</p><p>Above the Layout tab is the “Appearance” tab. Here, you can play with different settings for the node and edge colors, sizes and labels. These can be configured based upon attributes (including the stats you get Gephi to calculate).</p><p>As a suggestion, you could:</p><ul><li>Color the nodes by their Modularity attribute. This colors them according to their community membership.</li><li>Size the nodes by their Degree. Better connected nodes will appear larger than less connected ones.</li></ul><p>However, you should experiment and come up with a layout you like best.</p><p>Once you’re happy with the appearance of your graph, it is time to move on to the final step — exporting to Web!</p><h3 id="step-4-sigma-js">Step 4 — Sigma.js</h3><p>Already you have built a network visualisation that can be explored in Gephi. You could choose to take a screenshot, or save the graph in SVG, PDF or PNG format.</p><p>However, if you installed the Sigma.js plugin earlier, then why not export the graph to HTML? This will create an interactive visualisation that you can host online, or upload to GitHub and share with others.</p><p>To do this, select “Export &gt; Sigma.js template…” from Gephi’s menu bar.</p><p>Fill in the details as required. Make sure to choose which directory you export the project to. You can change the title, legend, description, hover behavior and many other details. When you’re ready, click “OK”.</p><p>Now, if you navigate to the directory you exported the project to, you will see a folder containing all the files generated by Sigma.js.</p><p>Open up <code>index.html</code> in your favorite browser. Ta-da! There’s your network! If you know a little CSS and JavaScript, you can dive into the various generated files to tweak the output as you wish.</p><p>And that concludes this tutorial!</p><h3 id="summary">Summary</h3><ul><li>Many systems can be modelled and visualised as networks. Graph theory is a branch of math that provides tools to help understand network structures and properties.</li><li>You used Python to scrape data from Wikipedia to build a programming languages influence graph. The linkage criterion was whether a given language was listed as an influence on another’s design.</li><li>Gephi and Sigma.js are open-source tools that allow you to analyze and visualize networks. They allow you to export the network in image, PDF or Web formats.</li></ul><p>Thanks for reading — I look forward to any comments or questions you might have! For a fantastic resource to learn more about graph theory, see <a href="https://en.wikipedia.org/wiki/Albert-L%C3%A1szl%C3%B3_Barab%C3%A1si" rel="noopener">Albert-László Barabási</a>’s interactive <a href="http://barabasi.com/networksciencebook/" rel="noopener">online book</a>.</p><p>The full code for this tutorial can be found <a href="https://gist.github.com/anonymous/2a6c841fe04ebc6d55acc259b4ac4f72" rel="noopener">here</a>.</p>
</div>
<hr>
<hr>
</section>
</article>
</div>
</main>
</div>
<!-- Google Tag Manager (noscript) -->
<!-- End Google Tag Manager (noscript) -->
