---
card: "https://cdn-media-1.freecodecamp.org/images/1*fp0t2D3aV_oHb6a94fp5Zg.png"
tags: [Machine Learning]
description: "by Nishit Jain"
author: "Milad E. Fahmy"
title: "An overview of the Gradient Descent algorithm"
created: "2021-08-16T11:29:42+02:00"
modified: "2021-08-16T11:29:42+02:00"
---
<div class="site-wrapper">
<main id="site-main" class="site-main outer">
<div class="inner">
<article class="post-full post tag-machine-learning tag-gradient-descent tag-data-science tag-technology tag-algorithms ">
<header class="post-full-header">
<h1 class="post-full-title">An overview of the Gradient Descent algorithm</h1>
</header>
<figure class="post-full-image">
<picture>
<source media="(max-width: 700px)" sizes="1px" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 1w">
<source media="(min-width: 701px)" sizes="(max-width: 800px) 400px,
(max-width: 1170px) 700px,
1400px" srcset="https://cdn-media-1.freecodecamp.org/images/1*fp0t2D3aV_oHb6a94fp5Zg.png 300w,
https://cdn-media-1.freecodecamp.org/images/1*fp0t2D3aV_oHb6a94fp5Zg.png 600w,
https://cdn-media-1.freecodecamp.org/images/1*fp0t2D3aV_oHb6a94fp5Zg.png 1000w,
https://cdn-media-1.freecodecamp.org/images/1*fp0t2D3aV_oHb6a94fp5Zg.png 2000w">
<img onerror="this.style.display='none'" src="https://cdn-media-1.freecodecamp.org/images/1*fp0t2D3aV_oHb6a94fp5Zg.png" alt="An overview of the Gradient Descent algorithm">
</picture>
</figure>
<section class="post-full-content">
<div class="post-content medium-migrated-article">
<p>by Nishit Jain</p><h1 id="an-overview-of-the-gradient-descent-algorithm"><strong>An overview of the Gradient Descent algorithm</strong></h1><h4 id="the-subtle-yet-powerful-algorithm-that-optimizes-parameters">The subtle yet powerful algorithm that optimizes parameters</h4><p>Optimizing parameters is the ultimate goal of every machine learning algorithm. You want to get the optimum value of the slope and the intercept to get the line of best fit in linear regression problems. You also want to get the optimum value for the parameters of a sigmoidal curve in logistic regression problems. So what if I told you that Gradient Descent does it all?</p>
</div>
<hr>
</section>
</article>
</div>
</main>
</div>
<!-- Google Tag Manager (noscript) -->
<!-- End Google Tag Manager (noscript) -->
